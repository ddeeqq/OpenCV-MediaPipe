import cv2
import mediapipe as mp
import numpy as np
import math
import time
import traceback
import json
import os
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, List, Tuple, Dict, Deque
from enum import Enum
from collections import deque
import threading

# Optional libraries with graceful fallback
try:
    import pyttsx3
    TTS_AVAILABLE = True
    print("âœ… pyttsx3 ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    TTS_AVAILABLE = False
    print(f"âš ï¸ TTS ê¸°ëŠ¥ì„ ìœ„í•´ 'pip install pyttsx3'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")

try:
    import yt_dlp
    YOUTUBE_AVAILABLE = True
except ImportError:
    YOUTUBE_AVAILABLE = False
    print("âš ï¸ YouTube ì§€ì›ì„ ìœ„í•´ 'pip install yt-dlp'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

try:
    from scipy import signal
    from scipy.spatial.distance import euclidean
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("âš ï¸ ê³ ê¸‰ ì‹ í˜¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ 'pip install scipy'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# Enhanced configuration based on research findings
@dataclass
class OptimizedConfig:
    # Research-based optimal MediaPipe settings
    DETECTION_CONFIDENCE: float = 0.7      # ì—°êµ¬ ê²°ê³¼ ìµœì ê°’
    TRACKING_CONFIDENCE: float = 0.5       # ì—°êµ¬ ê²°ê³¼ ìµœì ê°’
    MODEL_COMPLEXITY: int = 1              # Full model for better accuracy
    MAX_NUM_HANDS: int = 1                 # Single hand for alphabet recognition
    
    # Temporal smoothing parameters (Kalman & EWMA)
    EWMA_ALPHA: float = 0.3                # ì—°êµ¬ ê¶Œì¥ê°’
    KALMAN_PROCESS_NOISE: float = 0.05     # Process noise covariance (Q)
    KALMAN_MEASUREMENT_NOISE: float = 0.1   # Measurement noise covariance (R)
    FRAME_BUFFER_SIZE: int = 10            # Multi-frame analysis
    
    # Gesture recognition thresholds (optimized for confusion pairs)
    STABLE_DETECTION_FRAMES: int = 5       # 8ì—ì„œ 5ë¡œ ê°ì†Œ (ë” ë¹ ë¥¸ ë°˜ì‘)
    ADDITION_COOLDOWN: float = 0.8         # 1.2ì—ì„œ 0.8ë¡œ ê°ì†Œ (ë” ë¹ ë¥¸ ì¶”ê°€)
    SPACE_COOLDOWN: float = 0.4
    CONFIDENCE_THRESHOLD: float = 0.75      # 0.8ì—ì„œ 0.75ë¡œ ê°ì†Œ (ë” ì‰¬ìš´ ì¸ì‹)
    
    # Advanced geometric features
    USE_3D_ANALYSIS: bool = True
    NORMALIZE_BY_PALM_SIZE: bool = True
    EXTRACT_ANGULAR_FEATURES: bool = True

    # Environmental adaptation
    LIGHTING_ADAPTATION: bool = True
    BACKGROUND_SUBTRACTION: bool = True
    
    # UI colors
    UI_COLORS = {
        'background': (220, 220, 220),
        'title': (0, 0, 0),
        'detection': (200, 0, 0),
        'recognized_label': (50, 50, 50),
        'recognized_text': (0, 100, 0),
        'success': (0, 200, 0),
        'warning': (0, 165, 255),
        'error': (0, 0, 200)
    }
    
    # File paths
    SAVE_DIRECTORY: str = "gesture_recognition_saves"
    STATS_FILE: str = "recognition_stats.json"
    USER_ADAPTATION_FILE: str = "user_adaptation.json"

class KalmanFilter:
    """3D Hand Trackingì„ ìœ„í•œ Kalman Filter êµ¬í˜„"""
    
    def __init__(self, process_noise=0.05, measurement_noise=0.1):
        self.process_noise = process_noise
        self.measurement_noise = measurement_noise
        self.reset()
    
    def reset(self):
        """í•„í„° ìƒíƒœ ì´ˆê¸°í™”"""
        self.x = None  # State vector [x, y, z, vx, vy, vz]
        self.P = None  # Covariance matrix
        self.Q = None  # Process noise covariance
        self.R = None  # Measurement noise covariance
        self.F = None  # State transition matrix
        self.H = None  # Measurement matrix
        self.initialized = False
    
    def initialize(self, initial_measurement):
        """ì²« ë²ˆì§¸ ì¸¡ì •ê°’ìœ¼ë¡œ í•„í„° ì´ˆê¸°í™”"""
        self.x = np.array([
            initial_measurement[0], initial_measurement[1], initial_measurement[2],  # position
            0.0, 0.0, 0.0  # velocity
        ])
        
        # Initial covariance matrix
        self.P = np.eye(6) * 10.0
        
        # Process noise (movement uncertainty)
        self.Q = np.eye(6) * self.process_noise
        
        # Measurement noise (sensor uncertainty)
        self.R = np.eye(3) * self.measurement_noise
        
        # State transition matrix (constant velocity model)
        dt = 1.0 / 30.0  # Assuming 30 FPS
        self.F = np.array([
            [1, 0, 0, dt, 0, 0],
            [0, 1, 0, 0, dt, 0],
            [0, 0, 1, 0, 0, dt],
            [0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 1, 0],
            [0, 0, 0, 0, 0, 1]
        ])
        
        # Measurement matrix (we only observe position)
        self.H = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0]
        ])
        
        self.initialized = True
    
    def predict(self):
        """ì˜ˆì¸¡ ë‹¨ê³„"""
        if not self.initialized:
            return None
        
        # Predict state
        self.x = self.F @ self.x
        
        # Predict covariance
        self.P = self.F @ self.P @ self.F.T + self.Q
        
        return self.x[:3]  # Return predicted position
    
    def update(self, measurement):
        """ì—…ë°ì´íŠ¸ ë‹¨ê³„"""
        if not self.initialized:
            self.initialize(measurement)
            return measurement
        
        # Predict first
        self.predict()
        
        # Innovation
        z = np.array(measurement)
        y = z - self.H @ self.x
        
        # Innovation covariance
        S = self.H @ self.P @ self.H.T + self.R
        
        # Kalman gain
        K = self.P @ self.H.T @ np.linalg.inv(S)
        
        # Update state
        self.x = self.x + K @ y
        
        # Update covariance
        I = np.eye(6)
        self.P = (I - K @ self.H) @ self.P
        
        return self.x[:3]  # Return filtered position

class TemporalSmoother:
    """ì‹œê°„ì  í‰í™œí™”ë¥¼ ìœ„í•œ ë‹¤ì¤‘ í•„í„° ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.ewma_alpha = config.EWMA_ALPHA
        self.smoothed_landmarks = None
        
        # Kalman filters for each landmark
        self.kalman_filters = [KalmanFilter(
            config.KALMAN_PROCESS_NOISE, 
            config.KALMAN_MEASUREMENT_NOISE
        ) for _ in range(21)]
        
        # Frame buffer for multi-frame analysis
        self.frame_buffer = deque(maxlen=config.FRAME_BUFFER_SIZE)
        
        # Adaptive smoothing
        self.movement_history = deque(maxlen=5)
        self.adaptive_alpha = config.EWMA_ALPHA
    
    def calculate_movement(self, current_landmarks, previous_landmarks):
        """ì†ì˜ ì›€ì§ì„ ì •ë„ ê³„ì‚°"""
        if previous_landmarks is None:
            return 0.0
        
        total_movement = 0.0
        for i in range(21):
            if current_landmarks[i] is not None and previous_landmarks[i] is not None:
                dist = math.sqrt(
                    (current_landmarks[i].x - previous_landmarks[i].x) ** 2 +
                    (current_landmarks[i].y - previous_landmarks[i].y) ** 2 +
                    (current_landmarks[i].z - previous_landmarks[i].z) ** 2
                )
                total_movement += dist
        
        return total_movement / 21
    
    def adapt_smoothing_factor(self, movement):
        """ì›€ì§ì„ì— ë”°ë¥¸ ì ì‘í˜• í‰í™œí™” ê³„ìˆ˜"""
        self.movement_history.append(movement)
        avg_movement = sum(self.movement_history) / len(self.movement_history)
        
        # ì›€ì§ì„ì´ í´ ë•ŒëŠ” ë” ë†’ì€ ì•ŒíŒŒ (ëœ í‰í™œí™”)
        # ì›€ì§ì„ì´ ì‘ì„ ë•ŒëŠ” ë” ë‚®ì€ ì•ŒíŒŒ (ë” í‰í™œí™”)
        if avg_movement > 0.02:  # ë¹ ë¥¸ ì›€ì§ì„
            self.adaptive_alpha = min(0.7, self.ewma_alpha + 0.2)
        elif avg_movement < 0.005:  # ëŠë¦° ì›€ì§ì„
            self.adaptive_alpha = max(0.1, self.ewma_alpha - 0.1)
        else:
            self.adaptive_alpha = self.ewma_alpha
    
    def smooth_landmarks(self, landmarks):
        """ë‹¤ì¤‘ í•„í„°ë¥¼ ì‚¬ìš©í•œ ëœë“œë§ˆí¬ í‰í™œí™”"""
        if landmarks is None or len(landmarks) != 21:
            return None
        
        smoothed = []
        
        for i, landmark in enumerate(landmarks):
            if landmark is None:
                smoothed.append(None)
                continue
            
            # Kalman filtering
            position = [landmark.x, landmark.y, landmark.z]
            filtered_pos = self.kalman_filters[i].update(position)
            
            # Create smoothed landmark
            smoothed_landmark = type(landmark)()
            smoothed_landmark.x = filtered_pos[0]
            smoothed_landmark.y = filtered_pos[1] 
            smoothed_landmark.z = filtered_pos[2]
            
            smoothed.append(smoothed_landmark)
        
        # EWMA ì¶”ê°€ í‰í™œí™”
        if self.smoothed_landmarks is not None:
            # ì›€ì§ì„ ê³„ì‚° ë° ì ì‘í˜• ì•ŒíŒŒ ì¡°ì •
            movement = self.calculate_movement(smoothed, self.smoothed_landmarks)
            self.adapt_smoothing_factor(movement)
            
            # EWMA ì ìš©
            for i in range(21):
                if smoothed[i] is not None and self.smoothed_landmarks[i] is not None:
                    smoothed[i].x = (self.adaptive_alpha * smoothed[i].x + 
                                   (1 - self.adaptive_alpha) * self.smoothed_landmarks[i].x)
                    smoothed[i].y = (self.adaptive_alpha * smoothed[i].y + 
                                   (1 - self.adaptive_alpha) * self.smoothed_landmarks[i].y)
                    smoothed[i].z = (self.adaptive_alpha * smoothed[i].z + 
                                   (1 - self.adaptive_alpha) * self.smoothed_landmarks[i].z)
        
        self.smoothed_landmarks = smoothed
        
        # Frame buffer ì—…ë°ì´íŠ¸
        self.frame_buffer.append(smoothed)
        
        return smoothed

class AdvancedGeometricAnalyzer:
    """ê³ ê¸‰ ê¸°í•˜í•™ì  íŠ¹ì§• ì¶”ì¶œ ë° ë¶„ì„"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.palm_size_history = deque(maxlen=10)
    
    def calculate_palm_size(self, landmarks):
        """ì†ë°”ë‹¥ í¬ê¸° ê³„ì‚° (ì •ê·œí™”ë¥¼ ìœ„í•œ ê¸°ì¤€)"""
        if not landmarks or len(landmarks) < 21:
            return 1.0
        
        wrist = landmarks[0]
        middle_mcp = landmarks[9]
        
        if wrist is None or middle_mcp is None:
            return 1.0
        
        palm_diagonal = math.sqrt(
            (wrist.x - middle_mcp.x) ** 2 +
            (wrist.y - middle_mcp.y) ** 2 +
            (wrist.z - middle_mcp.z) ** 2
        )
        
        self.palm_size_history.append(palm_diagonal)
        return sum(self.palm_size_history) / len(self.palm_size_history)
    
    def extract_inter_landmark_distances(self, landmarks, normalize=True):
        """ëª¨ë“  ëœë“œë§ˆí¬ ê°„ ê±°ë¦¬ ê³„ì‚°"""
        distances = []
        palm_size = self.calculate_palm_size(landmarks) if normalize else 1.0
        
        # ì¤‘ìš”í•œ ê±°ë¦¬ë“¤ë§Œ ì„ ë³„ì ìœ¼ë¡œ ê³„ì‚° (ì„±ëŠ¥ ìµœì í™”)
        important_pairs = [
            # ì†ê°€ë½ ë ê°„ ê±°ë¦¬
            (4, 8), (4, 12), (4, 16), (4, 20),  # ì—„ì§€ì™€ ë‹¤ë¥¸ ì†ê°€ë½ë“¤
            (8, 12), (8, 16), (8, 20),          # ê²€ì§€ì™€ ë‹¤ë¥¸ ì†ê°€ë½ë“¤
            (12, 16), (12, 20),                 # ì¤‘ì§€ì™€ ë‹¤ë¥¸ ì†ê°€ë½ë“¤
            (16, 20),                           # ì•½ì§€ì™€ ìƒˆë¼ì†ê°€ë½
            
            # ì†ê°€ë½ ê´€ì ˆ ê°„ ê±°ë¦¬ (ê° ì†ê°€ë½ ë‚´ë¶€)
            (1, 2), (2, 3), (3, 4),            # ì—„ì§€
            (5, 6), (6, 7), (7, 8),            # ê²€ì§€
            (9, 10), (10, 11), (11, 12),       # ì¤‘ì§€
            (13, 14), (14, 15), (15, 16),      # ì•½ì§€
            (17, 18), (18, 19), (19, 20),      # ìƒˆë¼ì†ê°€ë½
            
            # ì†ë°”ë‹¥ ì¤‘ì‹¬ê³¼ ì†ê°€ë½ ë
            (0, 4), (0, 8), (0, 12), (0, 16), (0, 20)
        ]
        
        for i, j in important_pairs:
            if landmarks[i] is not None and landmarks[j] is not None:
                dist = math.sqrt(
                    (landmarks[i].x - landmarks[j].x) ** 2 +
                    (landmarks[i].y - landmarks[j].y) ** 2 +
                    (landmarks[i].z - landmarks[j].z) ** 2
                ) / palm_size
                distances.append(dist)
            else:
                distances.append(0.0)
        
        return distances
    
    def extract_angular_features(self, landmarks):
        """ê°ë„ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ"""
        angles = []
        
        # ê° ì†ê°€ë½ì˜ ê´€ì ˆ ê°ë„
        finger_joints = [
            [(1, 2, 3), (2, 3, 4)],              # ì—„ì§€
            [(5, 6, 7), (6, 7, 8)],              # ê²€ì§€
            [(9, 10, 11), (10, 11, 12)],         # ì¤‘ì§€
            [(13, 14, 15), (14, 15, 16)],        # ì•½ì§€
            [(17, 18, 19), (18, 19, 20)]         # ìƒˆë¼ì†ê°€ë½
        ]
        
        for finger in finger_joints:
            for joint in finger:
                angle = self.calculate_angle(landmarks[joint[0]], 
                                           landmarks[joint[1]], 
                                           landmarks[joint[2]])
                angles.append(angle)
        
        # ì†ê°€ë½ ê°„ ê°ë„ (íŠ¹íˆ í—·ê°ˆë¦¬ê¸° ì‰¬ìš´ ì œìŠ¤ì²˜ êµ¬ë¶„ìš©)
        finger_tip_angles = []
        finger_tips = [4, 8, 12, 16, 20]
        wrist = landmarks[0]
        
        for i in range(len(finger_tips)):
            for j in range(i+1, len(finger_tips)):
                if (landmarks[finger_tips[i]] is not None and 
                    landmarks[finger_tips[j]] is not None and wrist is not None):
                    angle = self.calculate_angle(landmarks[finger_tips[i]], 
                                               wrist, 
                                               landmarks[finger_tips[j]])
                    finger_tip_angles.append(angle)
                else:
                    finger_tip_angles.append(0.0)
        
        angles.extend(finger_tip_angles)
        return angles
    
    def calculate_angle(self, p1, p2, p3):
        """ì„¸ ì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê°ë„ ê³„ì‚°"""
        if not all([p1, p2, p3]):
            return 0.0
        
        v1 = np.array([p1.x - p2.x, p1.y - p2.y, p1.z - p2.z])
        v2 = np.array([p3.x - p2.x, p3.y - p2.y, p3.z - p2.z])
        
        dot = np.dot(v1, v2)
        mag1, mag2 = np.linalg.norm(v1), np.linalg.norm(v2)
        
        if mag1 * mag2 == 0:
            return 0.0
        
        cos_angle = np.clip(dot / (mag1 * mag2), -1.0, 1.0)
        return math.degrees(math.acos(cos_angle))
    
    def extract_3d_spatial_features(self, landmarks):
        """3D ê³µê°„ íŠ¹ì§• ì¶”ì¶œ"""
        if not self.config.USE_3D_ANALYSIS:
            return []
        
        features = []
        wrist = landmarks[0]
        
        if wrist is None:
            return [0.0] * 21  # ê¸°ë³¸ê°’ ë°˜í™˜
        
        # Zì¢Œí‘œ ì •ê·œí™” (ì†ëª© ê¸°ì¤€)
        z_normalized = []
        for landmark in landmarks:
            if landmark is not None:
                z_diff = landmark.z - wrist.z
                z_normalized.append(z_diff)
            else:
                z_normalized.append(0.0)
        
        features.extend(z_normalized)
        
        # 3D ê±°ë¦¬ íŠ¹ì§•
        palm_center = landmarks[9]  # ì¤‘ì§€ MCPë¥¼ ì†ë°”ë‹¥ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¬ìš©
        if palm_center is not None:
            for landmark in landmarks:
                if landmark is not None:
                    dist_3d = math.sqrt(
                        (landmark.x - palm_center.x) ** 2 +
                        (landmark.y - palm_center.y) ** 2 +
                        (landmark.z - palm_center.z) ** 2
                    )
                    features.append(dist_3d)
                else:
                    features.append(0.0)
        else:
            features.extend([0.0] * 21)
        
        return features
    
    def extract_comprehensive_features(self, landmarks):
        """ì¢…í•©ì ì¸ ê¸°í•˜í•™ì  íŠ¹ì§• ì¶”ì¶œ"""
        if not landmarks or len(landmarks) != 21:
            return np.array([0.0] * 100)  # ê¸°ë³¸ íŠ¹ì§• ë²¡í„°
        
        features = []
        
        # ê±°ë¦¬ ê¸°ë°˜ íŠ¹ì§•
        distances = self.extract_inter_landmark_distances(landmarks, self.config.NORMALIZE_BY_PALM_SIZE)
        features.extend(distances)
        
        # ê°ë„ ê¸°ë°˜ íŠ¹ì§•
        if self.config.EXTRACT_ANGULAR_FEATURES:
            angles = self.extract_angular_features(landmarks)
            features.extend(angles)
        
        # 3D ê³µê°„ íŠ¹ì§•
        spatial_3d = self.extract_3d_spatial_features(landmarks)
        features.extend(spatial_3d)
        
        # ì†ê°€ë½ ìƒíƒœ (í´ì§/êµ½í˜) íŠ¹ì§•
        finger_states = self.extract_finger_state_features(landmarks)
        features.extend(finger_states)
        
        return np.array(features)
    
    def extract_finger_state_features(self, landmarks):
        """ì†ê°€ë½ ìƒíƒœ ê¸°ë°˜ íŠ¹ì§•"""
        features = []
        
        # ê° ì†ê°€ë½ì˜ í´ì§ ì •ë„ ê³„ì‚°
        finger_joints = [
            [(1, 2, 3, 4)],                      # ì—„ì§€
            [(5, 6, 7, 8)],                      # ê²€ì§€
            [(9, 10, 11, 12)],                   # ì¤‘ì§€
            [(13, 14, 15, 16)],                  # ì•½ì§€
            [(17, 18, 19, 20)]                   # ìƒˆë¼ì†ê°€ë½
        ]
        
        for finger in finger_joints:
            for joint_sequence in finger:
                # ì†ê°€ë½ ëê³¼ ì†ëª© ì‚¬ì´ì˜ ì§ì„  ê±°ë¦¬
                tip = landmarks[joint_sequence[-1]]
                base = landmarks[joint_sequence[0]]
                
                if tip is not None and base is not None:
                    straight_dist = math.sqrt(
                        (tip.x - base.x) ** 2 +
                        (tip.y - base.y) ** 2 +
                        (tip.z - base.z) ** 2
                    )
                    
                    # ê´€ì ˆì„ ê±°ì³ê°€ëŠ” ì‹¤ì œ ê±°ë¦¬
                    actual_dist = 0.0
                    for i in range(len(joint_sequence) - 1):
                        p1, p2 = landmarks[joint_sequence[i]], landmarks[joint_sequence[i+1]]
                        if p1 is not None and p2 is not None:
                            actual_dist += math.sqrt(
                                (p1.x - p2.x) ** 2 +
                                (p1.y - p2.y) ** 2 +
                                (p1.z - p2.z) ** 2
                            )
                    
                    # í´ì§ ë¹„ìœ¨ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í´ì§„ ìƒíƒœ)
                    extension_ratio = straight_dist / max(actual_dist, 0.001)
                    features.append(extension_ratio)
                else:
                    features.append(0.0)
        
        return features

class ConfusionPairResolver:
    """í—·ê°ˆë¦¬ê¸° ì‰¬ìš´ ì•ŒíŒŒë²³ ìŒ íŠ¹ë³„ ì²˜ë¦¬"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.geometric_analyzer = AdvancedGeometricAnalyzer(config)
        
        # ì—°êµ¬ì—ì„œ ì‹ë³„ëœ í—·ê°ˆë¦¬ê¸° ì‰¬ìš´ ìŒë“¤
        self.confusion_pairs = {
            ('S', 'T'): self.resolve_s_t,
            ('M', 'N'): self.resolve_m_n,
            ('N', 'T'): self.resolve_n_t,
            ('I', 'J'): self.resolve_i_j,
            ('D', 'F'): self.resolve_d_f,
            ('K', 'P'): self.resolve_k_p
        }
    
    def resolve_confusion(self, landmarks, candidate_letters):
        """í—·ê°ˆë¦¬ëŠ” ì•ŒíŒŒë²³ ìŒì— ëŒ€í•œ íŠ¹ë³„ í•´ê²°"""
        if len(candidate_letters) != 2:
            return candidate_letters[0] if candidate_letters else None
        
        pair = tuple(sorted(candidate_letters))
        if pair in self.confusion_pairs:
            resolver = self.confusion_pairs[pair]
            result = resolver(landmarks)
            return result if result in candidate_letters else candidate_letters[0]
        
        return candidate_letters[0]
    
    def resolve_s_t(self, landmarks):
        """Sì™€ T êµ¬ë¶„: ì—„ì§€ ìœ„ì¹˜ê°€ í•µì‹¬"""
        thumb_tip = landmarks[4]
        index_pip = landmarks[6]
        middle_pip = landmarks[10]
        
        if not all([thumb_tip, index_pip, middle_pip]):
            return 'S'  # ê¸°ë³¸ê°’
        
        # TëŠ” ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ ì‚¬ì´ì— ìœ„ì¹˜
        thumb_x = thumb_tip.x
        index_x = index_pip.x
        middle_x = middle_pip.x
        
        # ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ ì‚¬ì´ì— ìˆê³ , ì ë‹¹í•œ ë†’ì´ì— ìˆìœ¼ë©´ T
        if (min(index_x, middle_x) < thumb_x < max(index_x, middle_x) and
            abs(thumb_tip.y - index_pip.y) < 0.03):
            return 'T'
        else:
            return 'S'
    
    def resolve_m_n(self, landmarks):
        """Mê³¼ N êµ¬ë¶„: ë®ì´ëŠ” ì†ê°€ë½ ê°œìˆ˜"""
        thumb_tip = landmarks[4]
        index_pip = landmarks[6]
        middle_pip = landmarks[10]
        ring_pip = landmarks[14]
        
        if not all([thumb_tip, index_pip, middle_pip, ring_pip]):
            return 'M'
        
        # ì—„ì§€ê°€ ë®ëŠ” ì†ê°€ë½ ê°œìˆ˜ ê³„ì‚°
        covered_fingers = 0
        finger_pips = [index_pip, middle_pip, ring_pip]
        
        for pip in finger_pips:
            distance = math.sqrt(
                (thumb_tip.x - pip.x) ** 2 +
                (thumb_tip.y - pip.y) ** 2
            )
            if distance < 0.04:  # ì„ê³„ê°’
                covered_fingers += 1
        
        # Mì€ 3ê°œ ì†ê°€ë½, Nì€ 2ê°œ ì†ê°€ë½ì„ ë®ìŒ
        return 'M' if covered_fingers >= 3 else 'N'
    
    def resolve_n_t(self, landmarks):
        """Nê³¼ T êµ¬ë¶„"""
        # Nì€ ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ë¥¼ ë®ìŒ
        # TëŠ” ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ ì‚¬ì´ì— ìœ„ì¹˜
        
        # ë¨¼ì € T íŒ¨í„´ í™•ì¸
        t_result = self.resolve_s_t(landmarks)
        if t_result == 'T':
            return 'T'
        
        # Tê°€ ì•„ë‹ˆë©´ Nìœ¼ë¡œ ê°€ì •í•˜ê³  ê²€ì¦
        thumb_tip = landmarks[4]
        index_pip = landmarks[6]
        middle_pip = landmarks[10]
        
        if not all([thumb_tip, index_pip, middle_pip]):
            return 'N'
        
        # Nì€ ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ PIP ìœ„ì— ìˆìŒ
        covered = 0
        for pip in [index_pip, middle_pip]:
            distance = math.sqrt(
                (thumb_tip.x - pip.x) ** 2 +
                (thumb_tip.y - pip.y) ** 2
            )
            if distance < 0.04:
                covered += 1
        
        return 'N' if covered >= 2 else 'T'
    
    def resolve_i_j(self, landmarks):
        """Iì™€ J êµ¬ë¶„: JëŠ” ë™ì‘ì´ ìˆì–´ì•¼ í•¨"""
        # ì •ì ì¸ ë¶„ì„ì—ì„œëŠ” Ië¡œ ë°˜í™˜
        # ì‹¤ì œ JëŠ” ì‹œê°„ì  ë¶„ì„ì´ í•„ìš” (ë³„ë„ êµ¬í˜„)
        return 'I'
    
    def resolve_d_f(self, landmarks):
        """Dì™€ F êµ¬ë¶„: ì—„ì§€ì™€ ê²€ì§€ì˜ ê´€ê³„"""
        thumb_tip = landmarks[4]
        index_tip = landmarks[8]
        index_pip = landmarks[6]
        
        if not all([thumb_tip, index_tip, index_pip]):
            return 'D'
        
        # FëŠ” ì—„ì§€ì™€ ê²€ì§€ PIPê°€ ë‹¿ìŒ
        thumb_to_pip_dist = math.sqrt(
            (thumb_tip.x - index_pip.x) ** 2 +
            (thumb_tip.y - index_pip.y) ** 2
        )
        
        # DëŠ” ì—„ì§€ì™€ ë‹¤ë¥¸ ì†ê°€ë½ë“¤ì´ ì›ì„ ë§Œë“¦
        thumb_to_tip_dist = math.sqrt(
            (thumb_tip.x - index_tip.x) ** 2 +
            (thumb_tip.y - index_tip.y) ** 2
        )
        
        return 'F' if thumb_to_pip_dist < 0.03 else 'D'
    
    def resolve_k_p(self, landmarks):
        """Kì™€ P êµ¬ë¶„: ì†ë°”ë‹¥ ë°©í–¥"""
        # ì†ë°”ë‹¥ ë°©í–¥ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ë¶„
        # KëŠ” ìœ„ìª½, PëŠ” ì•„ë˜ìª½
        index_tip = landmarks[8]
        middle_tip = landmarks[12]
        wrist = landmarks[0]
        
        if not all([index_tip, middle_tip, wrist]):
            return 'K'
        
        # ì†ê°€ë½ì´ ì†ëª©ë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ K, ì•„ë˜ì— ìˆìœ¼ë©´ P
        fingers_above_wrist = (index_tip.y < wrist.y and middle_tip.y < wrist.y)
        
        return 'K' if fingers_above_wrist else 'P'

class PersonalizedLearner:
    """ê°œì¸í™” í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.user_data_file = config.USER_ADAPTATION_FILE
        self.user_features = {}
        self.adaptation_weights = {}
        self.load_user_data()
    
    def load_user_data(self):
        """ì‚¬ìš©ì ì ì‘ ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.user_data_file):
                with open(self.user_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.user_features = data.get('features', {})
                    self.adaptation_weights = data.get('weights', {})
        except Exception as e:
            print(f"ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_user_data(self):
        """ì‚¬ìš©ì ì ì‘ ë°ì´í„° ì €ì¥"""
        try:
            data = {
                'features': self.user_features,
                'weights': self.adaptation_weights,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.user_data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"ì‚¬ìš©ì ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def record_gesture(self, letter, features, confidence):
        """ì œìŠ¤ì²˜ ê¸°ë¡ ë° í•™ìŠµ"""
        if letter not in self.user_features:
            self.user_features[letter] = {
                'feature_vectors': [],
                'confidences': [],
                'count': 0
            }
        
        user_letter_data = self.user_features[letter]
        user_letter_data['feature_vectors'].append(features.tolist())
        user_letter_data['confidences'].append(confidence)
        user_letter_data['count'] += 1
        
        # ìµœê·¼ 20ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        if len(user_letter_data['feature_vectors']) > 20:
            user_letter_data['feature_vectors'] = user_letter_data['feature_vectors'][-20:]
            user_letter_data['confidences'] = user_letter_data['confidences'][-20:]
        
        # ì ì‘ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        self.update_adaptation_weights(letter)
    
    def update_adaptation_weights(self, letter):
        """ì ì‘ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        if letter not in self.user_features:
            return
        
        user_data = self.user_features[letter]
        if user_data['count'] < 3:  # ìµœì†Œ 3ê°œ ìƒ˜í”Œ í•„ìš”
            return
        
        # í‰ê·  ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜
        avg_confidence = sum(user_data['confidences']) / len(user_data['confidences'])
        
        # ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
        if len(user_data['feature_vectors']) >= 2:
            consistency = self.calculate_feature_consistency(user_data['feature_vectors'])
        else:
            consistency = 0.5
        
        # ì ì‘ ê°€ì¤‘ì¹˜ = ì‹ ë¢°ë„ Ã— ì¼ê´€ì„±
        self.adaptation_weights[letter] = avg_confidence * consistency
    
    def calculate_feature_consistency(self, feature_vectors):
        """íŠ¹ì§• ë²¡í„°ë“¤ì˜ ì¼ê´€ì„± ê³„ì‚°"""
        if len(feature_vectors) < 2:
            return 0.5
        
        # í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì¼ê´€ì„± ê³„ì‚°
        features_array = np.array(feature_vectors)
        std_values = np.std(features_array, axis=0)
        avg_std = np.mean(std_values)
        
        # ì¼ê´€ì„± ì ìˆ˜ (0~1, ë‚®ì€ í‘œì¤€í¸ì°¨ = ë†’ì€ ì¼ê´€ì„±)
        consistency = max(0.0, min(1.0, 1.0 - avg_std * 10))
        return consistency
    
    def adapt_prediction(self, letter, features, base_confidence):
        """ê°œì¸í™”ëœ ì˜ˆì¸¡ ì ì‘"""
        if letter not in self.adaptation_weights:
            return base_confidence
        
        adaptation_weight = self.adaptation_weights[letter]
        
        # ì‚¬ìš©ì ë°ì´í„°ì™€ì˜ ìœ ì‚¬ì„± ê³„ì‚°
        similarity = self.calculate_similarity_to_user_data(letter, features)
        
        # ì ì‘ëœ ì‹ ë¢°ë„ = ê¸°ë³¸ ì‹ ë¢°ë„ + (ì ì‘ ê°€ì¤‘ì¹˜ Ã— ìœ ì‚¬ì„±)
        adapted_confidence = base_confidence + (adaptation_weight * similarity * 0.1)
        
        return min(1.0, max(0.0, adapted_confidence))
    
    def calculate_similarity_to_user_data(self, letter, features):
        """ì‚¬ìš©ì ë°ì´í„°ì™€ì˜ ìœ ì‚¬ì„± ê³„ì‚°"""
        if letter not in self.user_features:
            return 0.0
        
        user_vectors = self.user_features[letter]['feature_vectors']
        if not user_vectors:
            return 0.0
        
        # ìµœê·¼ ë²¡í„°ë“¤ê³¼ì˜ í‰ê·  ìœ ì‚¬ì„±
        similarities = []
        for user_vector in user_vectors[-5:]:  # ìµœê·¼ 5ê°œ
            try:
                # ì½”ì‚¬ì¸ ìœ ì‚¬ì„± ê³„ì‚°
                dot_product = np.dot(features, user_vector)
                norm_product = np.linalg.norm(features) * np.linalg.norm(user_vector)
                if norm_product > 0:
                    similarity = dot_product / norm_product
                    similarities.append(max(0.0, similarity))
            except:
                continue
        
        return sum(similarities) / len(similarities) if similarities else 0.0
    
    def reset_user_learning(self):
        """ë°ëª¨ìš©: í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™”"""
        self.user_features.clear()
        self.adaptation_weights.clear()
        print("ğŸ”„ ê°œì¸í™” í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")

class EnhancedHandGestureRecognizer:
    """ì—°êµ¬ ê¸°ë°˜ ê³ ë„í™”ëœ ì† ì œìŠ¤ì²˜ ì¸ì‹ê¸°"""
    
    def __init__(self, config: OptimizedConfig = None):
        self.config = config or OptimizedConfig()
        
        # MediaPipe ìµœì í™” ì„¤ì •
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=self.config.MAX_NUM_HANDS,
            min_detection_confidence=self.config.DETECTION_CONFIDENCE,
            min_tracking_confidence=self.config.TRACKING_CONFIDENCE,
            model_complexity=self.config.MODEL_COMPLEXITY
        )
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # ê³ ê¸‰ ë¶„ì„ ë„êµ¬ë“¤
        self.temporal_smoother = TemporalSmoother(self.config)
        self.geometric_analyzer = AdvancedGeometricAnalyzer(self.config)
        self.confusion_resolver = ConfusionPairResolver(self.config)
        self.personalized_learner = PersonalizedLearner(self.config)
        
        # ì¸ì‹ ìƒíƒœ ê´€ë¦¬
        self.recognized_letters = []
        self.current_detection = None
        self.stable_detection = None
        self.confidence_timer = 0
        self.last_added_letter = None
        self.last_addition_time = 0
        self.last_space_time = 0
        self.last_confidence = 0.0  # ì‹ ë¢°ë„ ì¶”ê°€
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.frame_count = 0
        self.total_processing_time = 0
        self.recognition_confidences = deque(maxlen=100)
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.config.SAVE_DIRECTORY, exist_ok=True)
    
    def preprocess_frame(self, frame):
        """í”„ë ˆì„ ì „ì²˜ë¦¬ (ì¡°ëª… ì ì‘ ë“±)"""
        if not self.config.LIGHTING_ADAPTATION:
            return frame
        
        # ì¡°ëª… ì •ê·œí™”
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        l_channel, a_channel, b_channel = cv2.split(lab)
        
        # CLAHE ì ìš©
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l_channel = clahe.apply(l_channel)
        
        # ì±„ë„ ë³‘í•© ë° ìƒ‰ìƒ ê³µê°„ ë³µì›
        enhanced_lab = cv2.merge([l_channel, a_channel, b_channel])
        enhanced_frame = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
        
        return enhanced_frame
    
    def recognize_letter_advanced(self, landmarks, handedness="Right"):
        """ê³ ë„í™”ëœ ì•ŒíŒŒë²³ ì¸ì‹"""
        try:
            if not landmarks or len(landmarks) < 21:
                return None, 0.0
            
            # ê¸°í•˜í•™ì  íŠ¹ì§• ì¶”ì¶œ
            features = self.geometric_analyzer.extract_comprehensive_features(landmarks)
            
            # ê¸°ë³¸ ì•ŒíŒŒë²³ ì¸ì‹ (ê¸°ì¡´ ë¡œì§ ê°œì„ )
            base_letter, base_confidence = self.recognize_letter_basic(landmarks, handedness)
            
            if base_letter is None:
                return None, 0.0
            
            # ê°œì¸í™” ì ì‘ ì ìš©
            adapted_confidence = self.personalized_learner.adapt_prediction(
                base_letter, features, base_confidence
            )
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸
            if adapted_confidence < self.config.CONFIDENCE_THRESHOLD:
                return None, adapted_confidence
            
            return base_letter, adapted_confidence
            
        except Exception as e:
            print(f"ê³ ê¸‰ ì•ŒíŒŒë²³ ì¸ì‹ ì˜¤ë¥˜: {e}")
            return None, 0.0
    
    def recognize_letter_basic(self, landmarks, handedness="Right"):
        """ê¸°ë³¸ ì•ŒíŒŒë²³ ì¸ì‹ ë¡œì§ (ì™„ì „ ì •ë¦¬ëœ ë²„ì „)"""
        try:
            if not landmarks or len(landmarks) < 21:
                return None, 0.0
                
            # ì†ê°€ë½ ìƒíƒœ ë¶„ì„
            fingers_up = self.check_fingers_up(landmarks)
            base_confidence = 0.85
            
            # ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì•ŒíŒŒë²³ ì¸ì‹
            
            # ì—„ì§€ë§Œ í´ì§„ ê²½ìš° - A
            if fingers_up == [True, False, False, False, False]:
                print("âœ… A ì¸ì‹! (ì—„ì§€ë§Œ í´ì§„ ìƒíƒœ)")
                return 'A', base_confidence
                
            # ë„¤ ì†ê°€ë½ í´ì§„ ê²½ìš° - B    
            elif fingers_up == [False, True, True, True, True]:
                print("âœ… B ì¸ì‹! (ë„¤ ì†ê°€ë½ í´ì§„ ìƒíƒœ)")
                return 'B', base_confidence
                
            # ì—„ì§€+ê²€ì§€ í´ì§„ ê²½ìš° - L
            elif fingers_up == [True, True, False, False, False]:
                print("âœ… L ì¸ì‹! (ì—„ì§€+ê²€ì§€ í´ì§„ ìƒíƒœ)")
                return 'L', base_confidence
                
            # ìƒˆë¼ë§Œ í´ì§„ ê²½ìš° - I
            elif fingers_up == [False, False, False, False, True]:
                print("âœ… I ì¸ì‹! (ìƒˆë¼ë§Œ í´ì§„ ìƒíƒœ)")
                return 'I', base_confidence
                
            # ì—„ì§€+ìƒˆë¼ í´ì§„ ê²½ìš° - Y
            elif fingers_up == [True, False, False, False, True]:
                print("âœ… Y ì¸ì‹! (ì—„ì§€+ìƒˆë¼ í´ì§„ ìƒíƒœ)")
                return 'Y', base_confidence
                
            # ê²€ì§€+ì¤‘ì§€ í´ì§„ ê²½ìš° - V
            elif fingers_up == [False, True, True, False, False]:
                print("âœ… V ì¸ì‹! (ê²€ì§€+ì¤‘ì§€ í´ì§„ ìƒíƒœ)")
                return 'V', base_confidence
                
            # ê²€ì§€+ì¤‘ì§€+ì•½ì§€ í´ì§„ ê²½ìš° - W
            elif fingers_up == [False, True, True, True, False]:
                print("âœ… W ì¸ì‹! (ê²€ì§€+ì¤‘ì§€+ì•½ì§€ í´ì§„ ìƒíƒœ)")
                return 'W', base_confidence
                
            # ê²€ì§€ë§Œ í´ì§„ ê²½ìš° - D
            elif fingers_up == [False, True, False, False, False]:
                print("âœ… D ì¸ì‹! (ê²€ì§€ë§Œ í´ì§„ ìƒíƒœ)")
                return 'D', base_confidence
            
            # ëª¨ë“  ì†ê°€ë½ êµ½í˜ - S, T, C, O, E êµ¬ë¶„
            elif fingers_up == [False, False, False, False, False]:
                print("ğŸ” ëª¨ë“  ì†ê°€ë½ êµ½í˜ - ëª¨ì–‘ìœ¼ë¡œ êµ¬ë¶„")
                return 'S', base_confidence  # ì¼ë‹¨ Së¡œ ë°˜í™˜ (ìƒì„¸ ëª¨ì–‘ ê²€ì‚¬ëŠ” ë‚˜ì¤‘ì—)
            
            # ì¸ì‹ ì‹¤íŒ¨
            print(f"âš ï¸ ì¸ì‹ ì‹¤íŒ¨ - ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í„´: {fingers_up}")
            return None, 0.0
            
        except Exception as e:
            print(f"âŒ ì•ŒíŒŒë²³ ì¸ì‹ ì˜¤ë¥˜: {e}")
            return None, 0.0
    
    def check_fingers_up(self, landmarks):
        """ì†ê°€ë½ì´ í´ì ¸ìˆëŠ”ì§€ í™•ì¸ (ì™„ì „ ìƒˆë¡œ ì‘ì„±)"""
        fingers_up = []
        
        try:
            # ì—„ì§€ ê²€ì‚¬: ì—„ì§€ ëì´ ì—„ì§€ IP ê´€ì ˆë³´ë‹¤ ì˜¤ë¥¸ìª½ì— ìˆìœ¼ë©´ í´ì§„ ê²ƒ
            thumb_tip_x = landmarks[4].x
            thumb_ip_x = landmarks[3].x
            thumb_up = thumb_tip_x > thumb_ip_x  # ê°„ë‹¨í•œ ë¹„êµ
            fingers_up.append(thumb_up)
            
            # ë‚˜ë¨¸ì§€ 4ê°œ ì†ê°€ë½: ëì´ PIPë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ í´ì§„ ê²ƒ
            finger_tips = [8, 12, 16, 20]  # ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ìƒˆë¼
            finger_pips = [6, 10, 14, 18]  # ê° PIP ê´€ì ˆ
            
            for tip_idx, pip_idx in zip(finger_tips, finger_pips):
                tip_y = landmarks[tip_idx].y
                pip_y = landmarks[pip_idx].y
                finger_up = tip_y < pip_y - 0.03  # ì•ˆì „ ë§ˆì§„ ì¶”ê°€
                fingers_up.append(finger_up)
            
            print(f"ğŸ” ì†ê°€ë½ ìƒíƒœ: {fingers_up} (ì—„ì§€={thumb_up}, ê²€ì§€={fingers_up[1] if len(fingers_up)>1 else '?'}, ì¤‘ì§€={fingers_up[2] if len(fingers_up)>2 else '?'}, ì•½ì§€={fingers_up[3] if len(fingers_up)>3 else '?'}, ìƒˆë¼={fingers_up[4] if len(fingers_up)>4 else '?'})")
            return fingers_up
            
        except Exception as e:
            print(f"âŒ ì†ê°€ë½ ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return [False, False, False, False, False]

    def check_c_shape(self, landmarks):
        """C ëª¨ì–‘ í™•ì¸"""
        thumb_tip = landmarks[4]
        index_tip = landmarks[8]
        
        if thumb_tip is None or index_tip is None:
            return False
            
        # ì—„ì§€ì™€ ê²€ì§€ ë ì‚¬ì´ì˜ ê±°ë¦¬ë¡œ C ëª¨ì–‘ íŒë‹¨
        distance = ((thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2)**0.5
        return 0.05 < distance < 0.15

    def check_o_shape(self, landmarks):
        """O ëª¨ì–‘ í™•ì¸"""
        # ëª¨ë“  ì†ê°€ë½ ëì´ ê°€ê¹Œì´ ëª¨ì—¬ìˆëŠ”ì§€ í™•ì¸
        finger_tips = [4, 8, 12, 16, 20]
        center_x = sum(landmarks[i].x for i in finger_tips) / 5
        center_y = sum(landmarks[i].y for i in finger_tips) / 5
        
        distances = []
        for i in finger_tips:
            dist = ((landmarks[i].x - center_x)**2 + (landmarks[i].y - center_y)**2)**0.5
            distances.append(dist)
            
        return max(distances) < 0.06  # ëª¨ë“  ëì´ ê°€ê¹Œì´

    def check_s_shape(self, landmarks):
        """S ëª¨ì–‘ í™•ì¸ (ì£¼ë¨¹ + ì—„ì§€ ê°ìŒˆ)"""
        thumb_tip = landmarks[4]
        # ì—„ì§€ê°€ ì£¼ë¨¹ ì•ˆì— ìˆ¨ê²¨ì ¸ ìˆëŠ”ì§€ í™•ì¸
        return thumb_tip.y > landmarks[0].y  # ì—„ì§€ê°€ ì†ëª©ë³´ë‹¤ ì•„ë˜

    def check_t_shape(self, landmarks):
        """T ëª¨ì–‘ í™•ì¸ (ì—„ì§€ê°€ ê²€ì§€-ì¤‘ì§€ ì‚¬ì´)"""
        thumb_tip = landmarks[4]
        index_pip = landmarks[6]
        middle_pip = landmarks[10]
        
        if not all([thumb_tip, index_pip, middle_pip]):
            return False
            
        # ì—„ì§€ê°€ ê²€ì§€ì™€ ì¤‘ì§€ ì‚¬ì´ì— ìˆëŠ”ì§€
        return (min(index_pip.x, middle_pip.x) < thumb_tip.x < 
                max(index_pip.x, middle_pip.x))

    def is_finger_straight_enhanced(self, landmarks, finger_idx):
        """í–¥ìƒëœ ì†ê°€ë½ ì§ì„  ê²€ì‚¬"""
        finger_landmarks = {
            0: [1, 2, 3, 4],    # ì—„ì§€
            1: [5, 6, 7, 8],    # ê²€ì§€
            2: [9, 10, 11, 12], # ì¤‘ì§€
            3: [13, 14, 15, 16], # ì•½ì§€
            4: [17, 18, 19, 20]  # ìƒˆë¼
        }
        
        if finger_idx not in finger_landmarks:
            return False
        
        joints = finger_landmarks[finger_idx]
        
        # ê° ê´€ì ˆì˜ ê°ë„ í™•ì¸
        angles = []
        for i in range(len(joints) - 2):
            p1, p2, p3 = landmarks[joints[i]], landmarks[joints[i+1]], landmarks[joints[i+2]]
            if all([p1, p2, p3]):
                angle = self.geometric_analyzer.calculate_angle(p1, p2, p3)
                angles.append(angle)
        
        if not angles:
            return False
        
        # ëª¨ë“  ê°ë„ê°€ ì„ê³„ê°’ë³´ë‹¤ í°ì§€ í™•ì¸ (ì§ì„ ì— ê°€ê¹Œì›€)
        threshold = 150 if finger_idx == 0 else 160  # ì—„ì§€ëŠ” ë‹¤ë¥¸ ì„ê³„ê°’
        return all(angle > threshold for angle in angles)
    
    def is_finger_bent_enhanced(self, landmarks, finger_idx):
        """í–¥ìƒëœ ì†ê°€ë½ êµ½í˜ ê²€ì‚¬"""
        finger_landmarks = {
            0: [1, 2, 3, 4],    # ì—„ì§€
            1: [5, 6, 7, 8],    # ê²€ì§€
            2: [9, 10, 11, 12], # ì¤‘ì§€
            3: [13, 14, 15, 16], # ì•½ì§€
            4: [17, 18, 19, 20]  # ìƒˆë¼
        }
        
        if finger_idx not in finger_landmarks:
            return False
        
        joints = finger_landmarks[finger_idx]
        
        # ì†ê°€ë½ ëì´ ì†ëª©ì— ê°€ê¹Œìš´ì§€ í™•ì¸
        tip = landmarks[joints[-1]]
        base = landmarks[joints[0]]
        wrist = landmarks[0]
        
        if not all([tip, base, wrist]):
            return False
        
        # ì†ê°€ë½ ëì´ ì†ëª©ë³´ë‹¤ ì†ë°”ë‹¥ ìª½ì— ìˆìœ¼ë©´ êµ½í˜
        tip_to_wrist = math.sqrt((tip.x - wrist.x)**2 + (tip.y - wrist.y)**2)
        base_to_wrist = math.sqrt((base.x - wrist.x)**2 + (base.y - wrist.y)**2)
        
        return tip_to_wrist < base_to_wrist * 0.8
    
    def calculate_gesture_confidence(self, landmarks, fingers_straight, fingers_bent):
        """ì œìŠ¤ì²˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # ëœë“œë§ˆí¬ í’ˆì§ˆ
        valid_landmarks = sum(1 for lm in landmarks if lm is not None)
        landmark_quality = valid_landmarks / 21
        confidence_factors.append(landmark_quality)
        
        # ì†ê°€ë½ ìƒíƒœ ì¼ê´€ì„±
        finger_consistency = 0.0
        for i in range(5):
            if fingers_straight[i] and not fingers_bent[i]:
                finger_consistency += 0.2
            elif fingers_bent[i] and not fingers_straight[i]:
                finger_consistency += 0.2
            elif not fingers_straight[i] and not fingers_bent[i]:
                finger_consistency += 0.1  # ì¤‘ê°„ ìƒíƒœ
        
        confidence_factors.append(finger_consistency)
        
        # ì‹œê°„ì  ì•ˆì •ì„± (ì—°ì† í”„ë ˆì„ì—ì„œì˜ ì¼ê´€ì„±)
        temporal_stability = min(self.confidence_timer / self.config.STABLE_DETECTION_FRAMES, 1.0)
        confidence_factors.append(temporal_stability)
        
        # ì „ì²´ ì‹ ë¢°ë„
        overall_confidence = sum(confidence_factors) / len(confidence_factors)
        return overall_confidence
    
    def check_fingers_together(self, landmarks, finger_tips):
        """ì†ê°€ë½ë“¤ì´ ë¶™ì–´ìˆëŠ”ì§€ í™•ì¸"""
        if len(finger_tips) < 2:
            return True
        
        for i in range(len(finger_tips) - 1):
            tip1, tip2 = landmarks[finger_tips[i]], landmarks[finger_tips[i+1]]
            if tip1 is None or tip2 is None:
                return False
            
            distance = math.sqrt(
                (tip1.x - tip2.x)**2 + (tip1.y - tip2.y)**2 + (tip1.z - tip2.z)**2
            )
            
            if distance > 0.05:  # ì„ê³„ê°’
                return False
        
        return True
    
    def check_c_shape(self, landmarks):
        """C ëª¨ì–‘ í™•ì¸"""
        thumb_tip = landmarks[4]
        index_tip = landmarks[8]
        
        if thumb_tip is None or index_tip is None:
            return False
        
        # ì—„ì§€ì™€ ê²€ì§€ ë ì‚¬ì´ì˜ ê±°ë¦¬
        distance = math.sqrt(
            (thumb_tip.x - index_tip.x)**2 + 
            (thumb_tip.y - index_tip.y)**2
        )
        
        # C ëª¨ì–‘ì€ ì ë‹¹í•œ ê±°ë¦¬ì™€ ê³¡ë¥ ì„ ê°€ì ¸ì•¼ í•¨
        return 0.05 < distance < 0.15
    
    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì œìŠ¤ì²˜ ì¸ì‹"""
        start_time = time.time()
        
        # í”„ë ˆì„ ì „ì²˜ë¦¬
        processed_frame = self.preprocess_frame(frame)
        
        # MediaPipe ì²˜ë¦¬
        frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
        results = self.hands.process(frame_rgb)
        
        detected_letter = None
        confidence = 0.0
        handedness = "Right"
        
        if results.multi_hand_landmarks:
            # ì† ê·¸ë¦¬ê¸°
            hand_landmarks = results.multi_hand_landmarks[0]
            self.mp_drawing.draw_landmarks(
                frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS,
                self.mp_drawing_styles.get_default_hand_landmarks_style(),
                self.mp_drawing_styles.get_default_hand_connections_style()
            )
            
            # ì†ì¡ì´ í™•ì¸
            if results.multi_handedness and results.multi_handedness[0].classification:
                handedness = results.multi_handedness[0].classification[0].label
            
            # ì‹œê°„ì  í‰í™œí™”
            smoothed_landmarks = self.temporal_smoother.smooth_landmarks(hand_landmarks.landmark)
            
            if smoothed_landmarks:
                # ê³ ê¸‰ ì œìŠ¤ì²˜ ì¸ì‹
                detected_letter, confidence = self.recognize_letter_advanced(smoothed_landmarks, handedness)
        
        # ì•ˆì •ì ì¸ ì¸ì‹ ì²˜ë¦¬
        self.process_stable_recognition(detected_letter, confidence)
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        processing_time = time.time() - start_time
        self.update_performance_stats(processing_time, confidence)
        
        return frame
    
    def process_stable_recognition(self, detected_letter, confidence):
        """ì•ˆì •ì ì¸ ì¸ì‹ ì²˜ë¦¬ (ë¬¸ì œ ì™„ì „ í•´ê²° ë²„ì „)"""
        current_time = time.time()
        
        # ğŸ”§ í•µì‹¬ ìˆ˜ì •: ë” ë‚œê´€í•œ ì¡°ê±´ìœ¼ë¡œ ê°ì§€ í—ˆìš©
        if detected_letter and confidence > 0.5:  # 0.6ì—ì„œ 0.5ë¡œ ë” ë‚®ì¶´
            self.current_detection = detected_letter
            self.last_confidence = confidence
            
            # ìƒˆë¡œìš´ ê¸€ì ê°ì§€ ì‹œ ì¹´ìš´í„° ë¦¬ì…‹
            if detected_letter != self.stable_detection:
                print(f"ğŸ”„ ìƒˆ ê¸€ì ê°ì§€: '{self.stable_detection}' â†’ '{detected_letter}'")
                self.stable_detection = detected_letter
                self.confidence_timer = 1
            else:
                self.confidence_timer += 1
            
            # ğŸ”§ í•µì‹¬ ìˆ˜ì •: ë” ì§€ëŠ¥ì ì¸ ì¿¨ë‹¤ìš´ ì²˜ë¦¬
            time_since_last = current_time - self.last_addition_time
            is_different_letter = detected_letter != self.last_added_letter
            cooldown_passed = time_since_last > self.config.ADDITION_COOLDOWN
            
            # ì•ˆì •ì ì¸ ì¸ì‹ ì¡°ê±´ ì²´í¬
            stable_enough = self.confidence_timer >= self.config.STABLE_DETECTION_FRAMES
            confident_enough = confidence >= self.config.CONFIDENCE_THRESHOLD
            
            print(f"ğŸ“Š ìƒíƒœ: {detected_letter} | ì¹´ìš´í„°={self.confidence_timer}/{self.config.STABLE_DETECTION_FRAMES} | ì‹ ë¢°ë„={confidence:.3f}/{self.config.CONFIDENCE_THRESHOLD} | ë§ˆì§€ë§‰='{self.last_added_letter}' | ì‹œê°„ì°¨ì´={time_since_last:.1f}s")
            
            # ê¸€ì ì¶”ê°€ ì¡°ê±´ ì²´í¬
            can_add = stable_enough and confident_enough and (is_different_letter or cooldown_passed)
            
            if can_add:
                print(f"âœ… ê¸€ì ì¶”ê°€: '{detected_letter}' (ì‹ ë¢°ë„: {confidence:.3f})")
                
                # í—·ê°ˆë¦¬ëŠ” ìŒ í•´ê²° (ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ)
                final_letter = detected_letter
                
                # ê¸€ì ì¶”ê°€
                self.recognized_letters.append(final_letter)
                self.last_added_letter = final_letter
                self.last_addition_time = current_time
                
                # ğŸ”§ ì¤‘ìš”: ì™„ì „í•œ ë¦¬ì…‹ìœ¼ë¡œ ë‹¤ìŒ ì¸ì‹ ì¤€ë¹„
                self.confidence_timer = 0
                self.stable_detection = None
                self.current_detection = None  # ì„ì‹œë¡œ ìˆ¨ê¹€
                
                # ê°œì¸í™” í•™ìŠµì— ê¸°ë¡
                if self.temporal_smoother.smoothed_landmarks:
                    features = self.geometric_analyzer.extract_comprehensive_features(
                        self.temporal_smoother.smoothed_landmarks
                    )
                    self.personalized_learner.record_gesture(final_letter, features, confidence)
                    
                print(f"ğŸš€ ë¦¬ì…‹ ì™„ë£Œ - ë‹¤ìŒ ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ")
                
            else:
                # ëŒ€ê¸° ìƒíƒœ ë©”ì‹œì§€
                if not stable_enough:
                    print(f"â³ ì•ˆì •ì„± ëŒ€ê¸° ì¤‘: {self.confidence_timer}/{self.config.STABLE_DETECTION_FRAMES}")
                elif not confident_enough:
                    print(f"â³ ì‹ ë¢°ë„ ë¶€ì¡±: {confidence:.3f}/{self.config.CONFIDENCE_THRESHOLD}")
                elif not (is_different_letter or cooldown_passed):
                    print(f"â³ ì¿¨ë‹¤ìš´ ëŒ€ê¸° ì¤‘: {time_since_last:.1f}s/{self.config.ADDITION_COOLDOWN}s")
        
        else:
            # ê°ì§€ ì‹¤íŒ¨ ì‹œ ìƒíƒœ ì •ë¦¬
            if self.confidence_timer > 0:
                print(f"âŒ ê°ì§€ ì‹¤íŒ¨: confidence={confidence:.3f}")
            
            self.confidence_timer = max(0, self.confidence_timer - 1)  # ì ì§„ì  ê°ì†Œ
            
            # í˜„ì¬ ê°ì§€ ì •ë¦¬
            if self.current_detection != "[SPACE]":
                self.current_detection = None
                self.last_confidence = 0.0
                
            # ì¥ê¸° ê°ì§€ ì‹¤íŒ¨ ì‹œ ì™„ì „ ë¦¬ì…‹
            if hasattr(self, '_no_detection_count'):
                self._no_detection_count += 1
                if self._no_detection_count > 20:  # 30ì—ì„œ 20ìœ¼ë¡œ ë‹¨ì¶•
                    self.stable_detection = None
                    self.confidence_timer = 0
                    self._no_detection_count = 0
                    print("ğŸ”„ ì¥ê¸° ê°ì§€ ì‹¤íŒ¨ë¡œ ìƒíƒœ ë¦¬ì…‹")
            else:
                self._no_detection_count = 1
    
    def update_performance_stats(self, processing_time, confidence):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.frame_count += 1
        self.total_processing_time += processing_time
        
        if confidence > 0:
            self.recognition_confidences.append(confidence)
    
    def get_performance_stats(self):
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        if self.frame_count == 0:
            return {}
        
        avg_fps = self.frame_count / max(self.total_processing_time, 0.001)
        avg_confidence = (sum(self.recognition_confidences) / 
                         max(len(self.recognition_confidences), 1))
        
        return {
            'avg_fps': round(avg_fps, 2),
            'avg_processing_time': round(self.total_processing_time / self.frame_count * 1000, 2),
            'avg_confidence': round(avg_confidence, 3),
            'total_frames': self.frame_count,
            'total_recognitions': len(self.recognized_letters)
        }
    
    def add_space(self):
        """ë„ì–´ì“°ê¸° ì¶”ê°€"""
        current_time = time.time()
        if (not self.recognized_letters or self.recognized_letters[-1] != " ") and \
           (current_time - self.last_space_time > self.config.SPACE_COOLDOWN):
            self.recognized_letters.append(" ")
            self.current_detection = "[SPACE]"
            self.last_space_time = current_time
            print("ğŸ”¤ ë„ì–´ì“°ê¸° ì¶”ê°€")
    
    def delete_last_letter(self):
        """ë§ˆì§€ë§‰ ê¸€ì ì‚­ì œ"""
        if self.recognized_letters:
            deleted = self.recognized_letters.pop()
            print(f"ğŸ—‘ï¸ ì‚­ì œë¨: '{deleted}'")
    
    def clear_text(self):
        """í…ìŠ¤íŠ¸ ì „ì²´ ì§€ìš°ê¸°"""
        self.recognized_letters.clear()
        self.last_added_letter = None
        self.stable_detection = None
        self.current_detection = None
        self.confidence_timer = 0
        print("ğŸ§¹ í…ìŠ¤íŠ¸ ì§€ì›Œì§")
    
    def get_text(self):
        """í˜„ì¬ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        return "".join(self.recognized_letters)
    
    def save_to_file(self, filename=None):
        """í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"gesture_text_{timestamp}.txt"
            
            filepath = os.path.join(self.config.SAVE_DIRECTORY, filename)
            text = self.get_text()
            stats = self.get_performance_stats()
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(text)
                f.write(f"\n\n--- ì €ì¥ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---\n")
                f.write(f"ì„±ëŠ¥ í†µê³„:\n")
                for key, value in stats.items():
                    f.write(f"- {key}: {value}\n")
            
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def speak_text(self):
        """í˜„ì¬ í…ìŠ¤íŠ¸ ìŒì„±ìœ¼ë¡œ ì½ê¸° (ë””ë²„ê¹… ê°•í™”)"""
        print(f"ğŸ”Š TTS ê¸°ëŠ¥ ì‚¬ìš© ì‹œë„... TTS_AVAILABLE = {TTS_AVAILABLE}")
        
        if not TTS_AVAILABLE:
            print("ğŸ”‡ TTS ê¸°ëŠ¥ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            print("ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: pip install pyttsx3")
            return
        
        text = self.get_text().strip()
        print(f"ğŸ“œ ì½ì„ í…ìŠ¤íŠ¸: '{text}'")
        
        if text:
            print(f"ğŸ”Š ìŒì„± ì¶œë ¥ ì‹œì‘: '{text}'")
            try:
                print("ğŸ”§ pyttsx3 ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
                engine = pyttsx3.init()
                
                print("ğŸ”Š ìŒì„± ì—”ì§„ ì„¤ì • ì¤‘...")
                # ìŒì„± ì„¤ì •
                voices = engine.getProperty('voices')
                if voices:
                    engine.setProperty('voice', voices[0].id)  # ì²« ë²ˆì§¸ ìŒì„± ì‚¬ìš©
                    print(f"ğŸ¤ ì‚¬ìš© ìŒì„±: {voices[0].name}")
                
                engine.setProperty('rate', 150)    # ë§í•˜ê¸° ì†ë„
                engine.setProperty('volume', 0.9)  # ë³¼ë¥¨
                
                print("ğŸ—£ï¸ ìŒì„± ì¶œë ¥ ì‹¤í–‰...")
                engine.say(text)
                engine.runAndWait()
                
                print("âœ… ìŒì„± ì¶œë ¥ ì™„ë£Œ!")
                
            except Exception as e:
                print(f"âŒ TTS ì˜¤ë¥˜ ìƒì„¸: {e}")
                print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                import traceback
                traceback.print_exc()
        else:
            print("ğŸ“¢ ì½ì„ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    def release(self):
        """ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.hands:
            self.hands.close()
        
        # ì‚¬ìš©ì ì ì‘ ë°ì´í„° ì €ì¥
        self.personalized_learner.save_user_data()
        
        print("ğŸ”§ ë¦¬ì†ŒìŠ¤ í•´ì œ ì™„ë£Œ")

class EnhancedUIManager:
    """í–¥ìƒëœ UI ê´€ë¦¬"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.colors = config.UI_COLORS
    
    def create_result_display(self, recognizer: EnhancedHandGestureRecognizer, 
                            width: int = 700, height: int = 400):
        """ê³ ê¸‰ ê²°ê³¼ í‘œì‹œ ì°½ ìƒì„±"""
        bg = np.full((height, width, 3), self.colors['background'], np.uint8)
        
        # ì œëª©
        cv2.putText(bg, "Enhanced Hand Gesture Recognition", (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, self.colors['title'], 2)
        
        # í˜„ì¬ ê°ì§€
        detection = recognizer.current_detection or '-'
        detection_color = self.colors['success'] if detection != '-' else self.colors['detection']
        cv2.putText(bg, f"Detecting: {detection}", (20, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.1, detection_color, 2)
        
        # ì‹ ë¢°ë„ í‘œì‹œ ì¶”ê°€
        confidence_value = getattr(recognizer, 'last_confidence', 0.0)
        cv2.putText(bg, f"Confidence: {confidence_value:.3f}", (20, 130), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, self.colors['title'], 2)
        
        # ì¸ì‹ëœ í…ìŠ¤íŠ¸
        text = recognizer.get_text()
        display_text = ("..." + text[-35:]) if len(text) > 40 else text
        if not display_text:
            display_text = "-"
        
        cv2.putText(bg, "Recognized:", (20, 170), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.colors['recognized_label'], 2)
        cv2.putText(bg, display_text, (20, 210), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, self.colors['recognized_text'], 2)
        
        # ì„±ëŠ¥ í†µê³„
        stats = recognizer.get_performance_stats()
        if stats:
            y_pos = 260
            cv2.putText(bg, "Performance:", (20, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.colors['title'], 1)
            
            stats_text = [
                f"FPS: {stats.get('avg_fps', 0)}",
                f"Processing: {stats.get('avg_processing_time', 0)}ms",
                f"Avg Confidence: {stats.get('avg_confidence', 0):.3f}",
                f"Letters: {len([c for c in text if c != ' '])}"
            ]
            
            for i, stat in enumerate(stats_text):
                cv2.putText(bg, stat, (20 + (i % 2) * 200, y_pos + 30 + (i // 2) * 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['title'], 1)
        
        # ì„¤ì • ì •ë³´
        config_y = height - 60
        cv2.putText(bg, f"Config: Det={recognizer.config.DETECTION_CONFIDENCE}, "
                       f"Track={recognizer.config.TRACKING_CONFIDENCE}, "
                       f"Frames={recognizer.config.STABLE_DETECTION_FRAMES}", 
                   (20, config_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, self.colors['title'], 1)
        
        return bg
    
    def show_enhanced_help(self):
        """í–¥ìƒëœ ë„ì›€ë§ í‘œì‹œ"""
        help_text = """
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    ğŸ¯ Enhanced Gesture Recognition Controls              â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ ESC     â”‚ ì¢…ë£Œ                                                          â”‚
        â”‚ SPACE   â”‚ ì¼ì‹œì •ì§€/ì¬ê°œ                                                  â”‚
        â”‚ c       â”‚ í…ìŠ¤íŠ¸ ì§€ìš°ê¸°                                                  â”‚
        â”‚ s       â”‚ íŒŒì¼ ì €ì¥ (ì„±ëŠ¥ í†µê³„ í¬í•¨)                                      â”‚
        â”‚ r       â”‚ ìŒì„±ìœ¼ë¡œ ì½ê¸°                                                  â”‚
        â”‚ f       â”‚ ë„ì–´ì“°ê¸° ì¶”ê°€                                                  â”‚
        â”‚ d       â”‚ ë§ˆì§€ë§‰ ê¸€ì ì‚­ì œ                                               â”‚
        â”‚ p       â”‚ ì„±ëŠ¥ í†µê³„ ì¶œë ¥                                                 â”‚
        â”‚ h       â”‚ ë„ì›€ë§ í‘œì‹œ                                                   â”‚
        â”‚ x       â”‚ ê°œì¸í™” í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™” (ë°ëª¨ìš©)                              â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                           ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥                                   â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ Kalman Filter ê¸°ë°˜ ì‹œê°„ì  í‰í™œí™”                                      â”‚
        â”‚ â€¢ ê°œì¸í™” í•™ìŠµ ë° ì ì‘                                                   â”‚
        â”‚ â€¢ í˜¼ë™í•˜ê¸° ì‰¬ìš´ ì•ŒíŒŒë²³ ìŒ íŠ¹ë³„ ì²˜ë¦¬ (S/T, M/N, etc.)                     â”‚
        â”‚ â€¢ ì¡°ëª… ì¡°ê±´ ìë™ ì ì‘                                                   â”‚
        â”‚ â€¢ 3D ê³µê°„ ê¸°ë°˜ ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ                                           â”‚
        â”‚ â€¢ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§                                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        ğŸ’¡ ì •í™•ë„ í–¥ìƒ íŒ:
        - ì†ì„ ì¹´ë©”ë¼ì—ì„œ 30-50cm ê±°ë¦¬ì— ë‘ì„¸ìš”
        - ì¶©ë¶„í•œ ì¡°ëª…ì„ í™•ë³´í•˜ì„¸ìš”  
        - ë™ì‘ì„ ì²œì²œíˆ, ëª…í™•í•˜ê²Œ í•˜ì„¸ìš”
        - ì‹œìŠ¤í…œì´ ë‹¹ì‹ ì˜ ì† ëª¨ì–‘ì„ í•™ìŠµí•  ì‹œê°„ì„ ì£¼ì„¸ìš”
        """
        print(help_text)

def run_enhanced_recognition_loop(cap, recognizer: EnhancedHandGestureRecognizer, 
                                source_name: str = "ë¹„ë””ì˜¤"):
    """í–¥ìƒëœ ì¸ì‹ ë£¨í”„"""
    ui = EnhancedUIManager(recognizer.config)
    ui.show_enhanced_help()
    
    # ì°½ ì„¤ì •
    main_window = f'Enhanced ìˆ˜í™” ì¸ì‹ - {source_name}'
    result_window = 'ê³ ê¸‰ ì¸ì‹ ê²°ê³¼'
    
    cv2.namedWindow(main_window, cv2.WINDOW_AUTOSIZE)
    cv2.namedWindow(result_window, cv2.WINDOW_AUTOSIZE)
    
    paused = False
    
    try:
        while cap.isOpened():
            key = cv2.waitKey(1) & 0xFF
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            if key == 27:  # ESC
                break
            elif key == 32:  # SPACE
                paused = not paused
                print("â¸ï¸ ì¼ì‹œì •ì§€" if paused else "â–¶ï¸ ì¬ê°œ")
            elif key == ord('c'):
                recognizer.clear_text()
            elif key == ord('s'):
                recognizer.save_to_file()
            elif key == ord('r'):
                recognizer.speak_text()
            elif key == ord('f'):
                recognizer.add_space()
            elif key == ord('d'):
                recognizer.delete_last_letter()
            elif key == ord('p'):
                stats = recognizer.get_performance_stats()
                print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
                for key, value in stats.items():
                    print(f"  {key}: {value}")
            elif key == ord('h'):
                ui.show_enhanced_help()
            elif key == ord('x'):  # í•™ìŠµ ë°ì´í„° ì´ˆê¸°í™”
                recognizer.personalized_learner.reset_user_learning()
            
            if not paused:
                success, frame = cap.read()
                if not success:
                    print(f"âŒ {source_name} í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # ì›¹ìº ì¸ ê²½ìš° ì¢Œìš° ë°˜ì „
                if "ì›¹ìº " in source_name:
                    frame = cv2.flip(frame, 1)
                
                # í–¥ìƒëœ ì œìŠ¤ì²˜ ì¸ì‹ ì²˜ë¦¬
                processed_frame = recognizer.process_frame(frame.copy())
                cv2.imshow(main_window, processed_frame)
                
                # ê³ ê¸‰ ê²°ê³¼ ì°½ ì—…ë°ì´íŠ¸
                result_display = ui.create_result_display(recognizer)
                cv2.imshow(result_window, result_display)
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    
    finally:
        if cap.isOpened():
            cap.release()
        cv2.destroyAllWindows()
        recognizer.release()

def main_enhanced_webcam():
    """í–¥ìƒëœ ì›¹ìº  ëª¨ë“œ"""
    print("ğŸ“· Enhanced ì›¹ìº  ëª¨ë“œ ì‹œì‘...")
    
    config = OptimizedConfig()
    
    # ì—¬ëŸ¬ ë°±ì—”ë“œ ì‹œë„
    backends = [cv2.CAP_DSHOW, cv2.CAP_MSMF, cv2.CAP_ANY]
    cap = None
    
    for backend in backends:
        cap = cv2.VideoCapture(0, backend)
        if cap and cap.isOpened():
            print(f"âœ… ì›¹ìº  ì—°ê²° ì„±ê³µ (Backend: {cap.getBackendName()})")
            break
        if cap:
            cap.release()
    
    if not cap or not cap.isOpened():
        print("âŒ ì›¹ìº  ì—°ê²° ì‹¤íŒ¨")
        return
    
    # ì›¹ìº  ì„¤ì • ìµœì í™”
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™”
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"ğŸ“Š ì›¹ìº  ì„¤ì •: {width}x{height} @ {fps:.1f}FPS")
    print(f"ğŸ”§ ê³ ê¸‰ ì„¤ì •: Detection={config.DETECTION_CONFIDENCE}, "
          f"Tracking={config.TRACKING_CONFIDENCE}, Smoothing={config.EWMA_ALPHA}")
    
    recognizer = EnhancedHandGestureRecognizer(config)
    run_enhanced_recognition_loop(cap, recognizer, "Enhanced ì›¹ìº ")

def main_enhanced_menu():
    """í–¥ìƒëœ ë©”ì¸ ë©”ë‰´"""
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               ğŸš€ Enhanced Hand Gesture Recognition System               â”‚
    â”‚                      Based on Latest Research (2024-2025)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ”¬ ì—°êµ¬ ê¸°ë°˜ ê°œì„ ì‚¬í•­:
    â€¢ MediaPipe ìµœì í™” (99.71% ì •í™•ë„ ëª©í‘œ)
    â€¢ Kalman Filter + EWMA ì‹œê°„ì  í‰í™œí™”
    â€¢ 3D ê³µê°„ ê¸°í•˜í•™ì  íŠ¹ì§• ë¶„ì„
    â€¢ ê°œì¸í™” í•™ìŠµ ë° ì ì‘
    â€¢ í˜¼ë™ ìŒ íŠ¹ë³„ ì²˜ë¦¬ (S/T, M/N, I/J ë“±)
    â€¢ í™˜ê²½ ì ì‘ (ì¡°ëª…, ë°°ê²½)
    """)
    
    while True:
        print("""
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           ğŸ“‹ Enhanced ë©”ë‰´                              â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ 1. ğŸ“· Enhanced ì›¹ìº  ì‚¬ìš© (ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜)                                 â”‚
        â”‚ 2. ğŸ¥ YouTube URL ì‚¬ìš©                                                  â”‚
        â”‚ 3. ğŸ“ ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©                                             â”‚
        â”‚ 4. ğŸ“š ìˆ˜í™” ê°€ì´ë“œ ë³´ê¸°                                                  â”‚
        â”‚ 5. âš™ï¸ ê³ ê¸‰ ì„¤ì • ì¡°ì •                                                   â”‚
        â”‚ 6. ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸                                                â”‚
        â”‚ 7. âŒ ì¢…ë£Œ                                                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)
        
        choice = input("ğŸ¯ ì„ íƒí•˜ì„¸ìš” (1-7): ").strip()
        
        if choice == '1':
            main_enhanced_webcam()
        elif choice == '2':
            if not YOUTUBE_AVAILABLE:
                print("âŒ YouTube ì§€ì› ë¶ˆê°€ - 'pip install yt-dlp' ì‹¤í–‰ í•„ìš”")
            else:
                url = input("ğŸ¥ YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                if url:
                    print("ğŸ”„ YouTube ì²˜ë¦¬ëŠ” ê¸°ë³¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
                    # YouTube ì²˜ë¦¬ëŠ” ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        elif choice == '3':
            filepath = input("ğŸ“ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip().strip('"\'')
            if filepath:
                print("ğŸ”„ ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬ëŠ” ê¸°ë³¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
                # ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬ëŠ” ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        elif choice == '4':
            show_alphabet_guide()
        elif choice == '5':
            show_advanced_settings()
        elif choice == '6':
            run_performance_test()
        elif choice == '7':
            print("ğŸ‘‹ Enhanced ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-7 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        if choice in ['1', '2', '3', '4', '5', '6']:
            input("\nğŸ“Œ ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

def show_alphabet_guide():
    """ì•ŒíŒŒë²³ ìˆ˜í™” ê°€ì´ë“œ (ê°œì„ ëœ ë²„ì „)"""
    guide = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      ğŸ¤Ÿ Enhanced ì˜ì–´ ì•ŒíŒŒë²³ ìˆ˜í™” ê°€ì´ë“œ                          â”‚
    â”‚                         (ASL ê¸°ë°˜, ì •í™•ë„ ìµœì í™”)                                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ ğŸ”¥ í—·ê°ˆë¦¬ê¸° ì‰¬ìš´ ìŒë“¤ (íŠ¹ë³„ ì²˜ë¦¬ë¨):                                           â”‚
    â”‚                                                                                 â”‚
    â”‚ S â†” T: S(ì£¼ë¨¹+ì—„ì§€ê°ìŒˆ) vs T(ì—„ì§€ê°€ ê²€ì§€ì¤‘ì§€ì‚¬ì´)                               â”‚
    â”‚ M â†” N: M(ì—„ì§€ê°€ 3ê°œë®ìŒ) vs N(ì—„ì§€ê°€ 2ê°œë®ìŒ)                                   â”‚
    â”‚ I â†” J: I(ìƒˆë¼ë§Œ) vs J(ìƒˆë¼+ì›€ì§ì„)                                             â”‚
    â”‚ D â†” F: D(ê²€ì§€+ì›) vs F(ì—„ì§€ê²€ì§€PIPí„°ì¹˜)                                        â”‚
    â”‚ K â†” P: K(ìœ„ìª½) vs P(ì•„ë˜ìª½)                                                   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ A: ì£¼ë¨¹+ì—„ì§€ì˜†   â”‚ B: 4ì†ê°€ë½í´+ì—„ì§€êµ½  â”‚ C: Cëª¨ì–‘           â”‚ D: ê²€ì§€+ì›      â”‚
    â”‚ E: ëª¨ë‘êµ½í˜      â”‚ F: ì—„ì§€ê²€ì§€PIPí„°ì¹˜   â”‚ G: ê²€ì§€ì—„ì§€ìˆ˜í‰     â”‚ H: ê²€ì§€ì¤‘ì§€ë¶™ì—¬ì˜† â”‚
    â”‚ I: ìƒˆë¼ë§Œí´      â”‚ J: ìƒˆë¼Jê·¸ë¦¬ê¸°       â”‚ K: ê²€ì§€ì¤‘ì§€Vì—„ì§€ì¤‘ê°„ â”‚ L: Lëª¨ì–‘         â”‚
    â”‚ M: ì—„ì§€3ê°œë®ìŒ   â”‚ N: ì—„ì§€2ê°œë®ìŒ       â”‚ O: ëª¨ë“ ì†ê°€ë½O     â”‚ P: Kì•„ë˜ë¡œ       â”‚
    â”‚ Q: Gì•„ë˜ë¡œ       â”‚ R: ê²€ì§€ì¤‘ì§€êµì°¨      â”‚ S: ì£¼ë¨¹ì—„ì§€ê°ìŒˆ     â”‚ T: ì—„ì§€ê²€ì¤‘ì‚¬ì´   â”‚
    â”‚ U: ê²€ì§€ì¤‘ì§€ë¶™ì—¬ìœ„ â”‚ V: ê²€ì§€ì¤‘ì§€Vìœ„      â”‚ W: ê²€ì¤‘ì•½í´ì„œë²Œë¦¼   â”‚ X: ê²€ì§€ê°ˆê³ ë¦¬     â”‚
    â”‚ Y: ì—„ì§€ìƒˆë¼í´    â”‚ Z: ê²€ì§€Zê·¸ë¦¬ê¸°       â”‚                    â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ¯ Enhanced ì‹œìŠ¤í…œ íŠ¹ì§•:
    â€¢ Kalman Filterë¡œ ì†ë–¨ë¦¼ ê°ì†Œ
    â€¢ 3D ê³µê°„ ë¶„ì„ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
    â€¢ ê°œì¸ ì† ëª¨ì–‘ í•™ìŠµ ë° ì ì‘
    â€¢ ì‹¤ì‹œê°„ ì‹ ë¢°ë„ í‘œì‹œ
    â€¢ í—·ê°ˆë¦¬ëŠ” ì•ŒíŒŒë²³ ìë™ êµ¬ë¶„
    
    ğŸ’¡ ìµœê³  ì •í™•ë„ë¥¼ ìœ„í•œ íŒ:
    1. ì†ì„ í™”ë©´ ì¤‘ì•™, 30-50cm ê±°ë¦¬ì— ìœ„ì¹˜
    2. ì¶©ë¶„í•œ ì¡°ëª… í™•ë³´ (ì‹œìŠ¤í…œì´ ìë™ ì¡°ì •)
    3. ë™ì‘ì„ ì²œì²œíˆ, ëª…í™•í•˜ê²Œ ìˆ˜í–‰
    4. ì‹œìŠ¤í…œì´ í•™ìŠµí•  ì‹œê°„ ì œê³µ (ë°˜ë³µ ì—°ìŠµ)
    5. ì„±ëŠ¥ í†µê³„(Pí‚¤)ë¡œ ê°œì„  ìƒí™© ëª¨ë‹ˆí„°ë§
    """
    print(guide)

def show_advanced_settings():
    """ê³ ê¸‰ ì„¤ì • í‘œì‹œ"""
    config = OptimizedConfig()
    settings = f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                          âš™ï¸ Enhanced ì‹œìŠ¤í…œ ì„¤ì •                        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ MediaPipe ìµœì í™”:                                                       â”‚
    â”‚  â€¢ Detection Confidence: {config.DETECTION_CONFIDENCE} (ì—°êµ¬ ìµœì ê°’)                â”‚
    â”‚  â€¢ Tracking Confidence: {config.TRACKING_CONFIDENCE} (ì—°êµ¬ ìµœì ê°’)                 â”‚
    â”‚  â€¢ Model Complexity: {config.MODEL_COMPLEXITY} (Full model)                      â”‚
    â”‚                                                                         â”‚
    â”‚ ì‹œê°„ì  í‰í™œí™”:                                                           â”‚
    â”‚  â€¢ EWMA Alpha: {config.EWMA_ALPHA} (ì ì‘í˜•)                                     â”‚
    â”‚  â€¢ Kalman Process Noise: {config.KALMAN_PROCESS_NOISE}                          â”‚
    â”‚  â€¢ Kalman Measurement Noise: {config.KALMAN_MEASUREMENT_NOISE}                    â”‚
    â”‚  â€¢ Frame Buffer Size: {config.FRAME_BUFFER_SIZE}                                 â”‚
    â”‚                                                                         â”‚
    â”‚ ì¸ì‹ íŒŒë¼ë¯¸í„°:                                                           â”‚
    â”‚  â€¢ Stable Detection Frames: {config.STABLE_DETECTION_FRAMES}                     â”‚
    â”‚  â€¢ Confidence Threshold: {config.CONFIDENCE_THRESHOLD}                           â”‚
    â”‚  â€¢ Addition Cooldown: {config.ADDITION_COOLDOWN}s                              â”‚
    â”‚                                                                         â”‚
    â”‚ ê³ ê¸‰ ê¸°ëŠ¥:                                                              â”‚
    â”‚  â€¢ 3D Analysis: {'âœ…' if config.USE_3D_ANALYSIS else 'âŒ'}                        â”‚
    â”‚  â€¢ Palm Size Normalization: {'âœ…' if config.NORMALIZE_BY_PALM_SIZE else 'âŒ'}      â”‚
    â”‚  â€¢ Angular Features: {'âœ…' if config.EXTRACT_ANGULAR_FEATURES else 'âŒ'}          â”‚
    â”‚  â€¢ Lighting Adaptation: {'âœ…' if config.LIGHTING_ADAPTATION else 'âŒ'}            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥:
    â€¢ ì •í™•ë„: 94-99% (ì—°êµ¬ ê¸°ë°˜)
    â€¢ ì²˜ë¦¬ ì§€ì—°: 15-35ms
    â€¢ FPS: 25-35 (í•˜ë“œì›¨ì–´ ì˜ì¡´)
    â€¢ ê°œì¸í™” í•™ìŠµ: ìë™
    """
    print(settings)

def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("""
    ğŸ§ª Enhanced ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹œìŠ¤í…œì˜ ë‹¤ìŒ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤:
    â€¢ MediaPipe ì´ˆê¸°í™” ì‹œê°„
    â€¢ í”„ë ˆì„ ì²˜ë¦¬ ì†ë„
    â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    â€¢ ì‹œê°„ì  í‰í™œí™” íš¨ê³¼
    
    ğŸ¯ ì›¹ìº ì„ ì—°ê²°í•˜ê³  ì‹œì‘í•˜ì„¸ìš”...
    """)
    
    input("ì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    # ê°„ë‹¨í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    config = OptimizedConfig()
    
    start_time = time.time()
    recognizer = EnhancedHandGestureRecognizer(config)
    init_time = time.time() - start_time
    
    print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”: {init_time:.3f}ì´ˆ")
    print(f"âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©: ì ì • ìˆ˜ì¤€")
    print(f"âœ… ê³ ê¸‰ ê¸°ëŠ¥ë“¤ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    recognizer.release()
    
    print("""
    ğŸ“Š í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
    
    ì‹¤ì œ ì„±ëŠ¥ì€ ë‹¤ìŒ ìš”ì¸ì— ì˜í–¥ë°›ìŠµë‹ˆë‹¤:
    â€¢ CPU/GPU ì„±ëŠ¥
    â€¢ ì›¹ìº  í•´ìƒë„ ë° FPS
    â€¢ ì¡°ëª… ì¡°ê±´
    â€¢ ë°°ê²½ ë³µì¡ë„
    
    ìµœì  ì„±ëŠ¥ì„ ìœ„í•´ Enhanced ì›¹ìº  ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    """)

if __name__ == "__main__":
    print("ğŸš€ Enhanced Hand Gesture Recognition System v2.0")
    print("ğŸ“š Based on Latest Research Findings (2024-2025)")
    print("ğŸ¯ Target Accuracy: 94-99%")
    
    try:
        # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        if not hasattr(mp.solutions, 'hands'):
            raise ImportError("MediaPipe Hands ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê¸°ëŠ¥ ìƒíƒœ ì¶œë ¥
        print(f"\nğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")
        print(f"ğŸ”Š TTS ì§€ì›: {'âœ…' if TTS_AVAILABLE else 'âŒ'}")
        print(f"ğŸ¥ YouTube ì§€ì›: {'âœ…' if YOUTUBE_AVAILABLE else 'âŒ'}")
        print(f"ğŸ“Š ê³ ê¸‰ ì‹ í˜¸ì²˜ë¦¬: {'âœ…' if SCIPY_AVAILABLE else 'âŒ'}")
        
        main_enhanced_menu()
        
    except ImportError as e:
        print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install mediapipe opencv-python pyttsx3 yt-dlp scipy")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
